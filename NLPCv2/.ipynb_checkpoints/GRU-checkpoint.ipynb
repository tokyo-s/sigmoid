{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71ec7bdf-7274-40a9-af0a-2b2b62a1d979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrierea și comentarea codului.           Done\n",
    "# Implimentarea clasei Vocabular.\n",
    "# Implimentarea clasei Data set.            Done\n",
    "# Implimentarea rețelei neuronale.          Done\n",
    "# Implimentarea ciclului de învănțare.      Done \n",
    "# Prezentța graficului cu Learning Curve pentru acuratețe și eroare.  Done\n",
    "# Reantrenarea modelului cu cem mai bun rezultat după learning curve. Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8878eea4-0353-4d75-859f-b61ed5bb1d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch import nn as nn\n",
    "from collections import Counter\n",
    "import gensim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "664ecd28-9384-4299-8881-f1f2f455dc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Implementing Dataset class\n",
    "# class Data(Dataset):\n",
    "#     def __init__(self, path):\n",
    "#         self.data = pd.read_csv(path, usecols = [2,3], names=['sentiment', 'content'])\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         return self.data.iloc[index].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4244c877-83cd-439e-906c-d90014422c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing Dataset class\n",
    "class Data(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.tensor(data.values)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95f80666-3cd9-4cef-98a9-874bad1c31b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary class\n",
    "class Vocabulary:\n",
    "    def __init__(self, path_to_train, path_to_test, tokenizer, stemmer):\n",
    "        self.train = pd.read_csv(path_to_train, usecols = [2,3], names=['sentiment', 'content'])\n",
    "        self.test = pd.read_csv(path_to_test, usecols = [2,3], names=['sentiment', 'content'])\n",
    "        self.tokenizer = tokenizer\n",
    "        self.stemmer = stemmer\n",
    "        self.trained = False\n",
    "    \n",
    "    def word2vec(self,):\n",
    "        model_train = gensim.models.Word2Vec(self.train['tokens'].sum(), min_count = 1, \n",
    "                              size = 100, window = 5)\n",
    "        \n",
    "        model_test = gensim.models.Word2Vec(self.test['tokens'].sum(), min_count = 1, \n",
    "                              size = 100, window = 5)\n",
    "    \n",
    "    def tokenize(self,):\n",
    "        pass\n",
    "    \n",
    "    def text2tokens(self):\n",
    "        # for i in range(len(self.train)):\n",
    "        #     self.train.iloc[i]['tokens'] = nltk.work_tokenize(self.train.iloc[i]['content'])\n",
    "        # for i in range(len(self.test)):\n",
    "        #     self.test.iloc[i]['tokens'] = nltk.work_tokenize(self.test.iloc[i]['content'])\n",
    "        self.train['tokens'] = self.train['content'].apply(lambda x: np.array([word.lower() for word in word_tokenize(str(x)) if len(word)>2]))\n",
    "        self.test['tokens'] = self.test['content'].apply(lambda x: np.array([word.lower() for word in word_tokenize(str(x)) if len(word)>2]))\n",
    "            \n",
    "    def remove_stop_words(self,):\n",
    "        # self.train['tokens'] = self.train['tokens'].apply(lambda x: x[x not in stopwords.words('english')])\n",
    "        # self.test['tokens'] = self.test['tokens'].apply(lambda x: x[x not in stopwords.words('english')])\n",
    "        self.train['tokens'] = self.train['tokens'].apply(lambda x: [word for word in x if word not in stopwords.words('english')])\n",
    "        self.test['tokens'] = self.test['tokens'].apply(lambda x: [word for word in x if word not in stopwords.words('english')])\n",
    "\n",
    "    def remove_hapaxes(self,):\n",
    "        all_words = sum(vocabulary.train['tokens'], [])\n",
    "        # counter = Counter(all_words)\n",
    "        fdist = FreqDist(all_words)\n",
    "        self.hapaxes = fdist.hapaxes()\n",
    "        self.train['tokens'] = self.train['tokens'].apply(lambda x: [word for word in x if word not in self.hapaxes])\n",
    "        self.test['tokens'] = self.test['tokens'].apply(lambda x: [word for word in x if word not in self.hapaxes])\n",
    "\n",
    "    \n",
    "    def stemming(self,):\n",
    "        self.train['tokens'] = self.train['tokens'].apply(lambda x: [self.stemmer.stem(word) for word in x])\n",
    "        self.test['tokens'] = self.test['tokens'].apply(lambda x: [self.stemmer.stem(word) for word in x])\n",
    "\n",
    "    def preprocess(self):\n",
    "        \n",
    "        self.text2tokens()\n",
    "        self.remove_stop_words()\n",
    "        self.remove_hapaxes()\n",
    "        self.stemming()\n",
    "        \n",
    "        new_train, new_test = self.tokenize()\n",
    "        \n",
    "        new_vec_train, new_vec_test = self.word2vec(new_train, new_test)\n",
    "        \n",
    "        return self.train[['tokens','sentiment']], self.test[['tokens','sentiment']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d91dccee-910f-4baa-b439-f15db4c1cb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network class\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, drop_prob=0.2):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, n_layers, batch_first=True, dropout=drop_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        out, h = self.gru(x, h)\n",
    "        out = self.fc(self.relu(out[:,-1]))\n",
    "        return out, h\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5da14e5d-7d1c-4b39-9101-1bb9feb6cd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train loop \n",
    "def train(epochs, optimizer, model, loss_fn, train_loader, test_loader, l2=0.001, print_plot=True):\n",
    "    \n",
    "    train_accuracy = np.zeros(epochs)\n",
    "    test_accuracy = np.zeros(epochs)\n",
    "    \n",
    "    train_loss = np.zeros(epochs)\n",
    "    test_loss = np. zeros(epochs)\n",
    "    for epoch in range(epochs):\n",
    "        # Train\n",
    "        model.train()\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        current_train_loss = 0.0\n",
    "        current_test_loss = 0.0\n",
    "\n",
    "        for example, labels in train_loader:     \n",
    "\n",
    "            #Translating calculations to gpu if is available\n",
    "            example = example.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "\n",
    "            # ensuring equal number of dimensions for labels and examples\n",
    "            labels  = labels.unsqueeze(1)\n",
    "\n",
    "            # running our data thru our data - forward\n",
    "            predicted, _ = model(example)\n",
    "            \n",
    "            # Getting loss of our network right now\n",
    "            loss = loss_fn(predicted, labels)\n",
    "            current_train_loss += loss    # Check if should not detatch?\n",
    "\n",
    "            total += labels.shape[0]\n",
    "            correct += int((predicted == labels).sum())\n",
    "            # l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "            # train_loss = train_loss + l2 *l2_norm\n",
    "\n",
    "            # Zeroing the gradient to not stack it from other iterations\n",
    "            optimizer.zero_grad()\n",
    "            #Runing backward part of the neural network, getting gradiets\n",
    "            train_loss.backward()\n",
    "            #Updating our paramters\n",
    "            optimizer.step()\n",
    "        \n",
    "        train_accuracy[epoch] = correct / total\n",
    "        train_loss[epoch] = current_train_loss\n",
    "        # Test\n",
    "        model.eval()\n",
    "        \n",
    "        for example, labels in test_loader:\n",
    "\n",
    "            #Translating calculations to gpu if is available\n",
    "            example = example.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            \n",
    "            # ensuring equal number of dimensions for labels and examples\n",
    "            labels  = labels.unsqueeze(1)\n",
    "\n",
    "            #Forward\n",
    "            val_output = model(example.float())\n",
    "            #Loss\n",
    "            loss = loss_fn(val_output, labels.float())\n",
    "            current_test_loss += loss # Check for detatch\n",
    "            \n",
    "            total += labels.shape[0]\n",
    "            correct += int((predicted == labels).sum())\n",
    "            \n",
    "        test_accuracy[epoch] = correct / total\n",
    "        test_loss[epoch] = current_test_loss\n",
    "        #Print results for epochs\n",
    "        if epoch % 10 == 0:\n",
    "            print('Epoch {0}, Training loss - {1}, Validation loss {2} \\n'.format(epoch,current_train_loss, current_test_loss))\n",
    "\n",
    "\n",
    "    #If set to True, print graph of train and validation loss\n",
    "    if print_plot:\n",
    "\n",
    "        #Setting x-ticks\n",
    "        epochs_range = range(1,epochs+1)\n",
    "        \n",
    "        fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "        \n",
    "        ax[0, 0].plot(epochs_range, train_loss, 'g', label='Training loss')\n",
    "        ax[0, 0].plot(epochs_range, test_loss, 'b', label='validation loss')\n",
    "        ax[0, 0].title('Training and Validation loss')\n",
    "        ax[0, 0].xlabel('Epochs')\n",
    "        ax[0, 0].ylabel('Loss')\n",
    "        ax[0, 0].legend()\n",
    "        \n",
    "        ax[0, 1].plot(epochs_range, train_accuracy, 'g', label='Training loss')\n",
    "        ax[0, 1].plot(epochs_range, test_accuracy, 'b', label='validation loss')\n",
    "        ax[0, 1].title('Training and Validation loss')\n",
    "        ax[0, 1].xlabel('Epochs')\n",
    "        ax[0, 1].ylabel('Loss')\n",
    "        ax[0, 1].legend()\n",
    "        \n",
    "        plt.show()\n",
    "        # #Ploting both curves, train and val \n",
    "        # plt.plot(epochs_range, train_loss, 'g', label='Training loss')\n",
    "        # plt.plot(epochs_range, test_loss, 'b', label='validation loss')\n",
    "        # plt.title('Training and Validation loss')\n",
    "        # plt.xlabel('Epochs')\n",
    "        # plt.ylabel('Loss')\n",
    "        # plt.legend()\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "558a2904-c231-410d-bbd5-590dfebd87ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "path_to_data = 'GRU/data'\n",
    "path_to_train = os.path.join(path_to_data, 'twitter_training.csv')\n",
    "path_to_test = os.path.join(path_to_data, 'twitter_validation.csv')\n",
    "\n",
    "# Applying the vocabulary\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "vocabulary = Vocabulary(path_to_train, path_to_test, tokenizer = None, stemmer = ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72b512ed-d196-4f45-b05c-eabf408ba283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.text2tokens()\n",
    "#         self.remove_stop_words()\n",
    "#         self.remove_hapaxes()\n",
    "#         self.stemming()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c94489a-c0e1-485e-a532-a1f02d300715",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary.text2tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa98bdb9-9bb1-4276-9b5c-c169579c911a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "      <td>[getting, borderlands, and, will, murder, you,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>[coming, the, borders, and, will, kill, you, all]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>[getting, borderlands, and, will, kill, you, all]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>[coming, borderlands, and, will, murder, you, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>[getting, borderlands, and, will, murder, you,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74677</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that the Windows partition of my...</td>\n",
       "      <td>[just, realized, that, the, windows, partition...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74678</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that my Mac window partition is ...</td>\n",
       "      <td>[just, realized, that, mac, window, partition,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74679</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized the windows partition of my Mac ...</td>\n",
       "      <td>[just, realized, the, windows, partition, mac,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74680</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized between the windows partition of...</td>\n",
       "      <td>[just, realized, between, the, windows, partit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74681</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just like the windows partition of my Mac is l...</td>\n",
       "      <td>[just, like, the, windows, partition, mac, lik...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74682 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                            content  \\\n",
       "0      Positive  im getting on borderlands and i will murder yo...   \n",
       "1      Positive  I am coming to the borders and I will kill you...   \n",
       "2      Positive  im getting on borderlands and i will kill you ...   \n",
       "3      Positive  im coming on borderlands and i will murder you...   \n",
       "4      Positive  im getting on borderlands 2 and i will murder ...   \n",
       "...         ...                                                ...   \n",
       "74677  Positive  Just realized that the Windows partition of my...   \n",
       "74678  Positive  Just realized that my Mac window partition is ...   \n",
       "74679  Positive  Just realized the windows partition of my Mac ...   \n",
       "74680  Positive  Just realized between the windows partition of...   \n",
       "74681  Positive  Just like the windows partition of my Mac is l...   \n",
       "\n",
       "                                                  tokens  \n",
       "0      [getting, borderlands, and, will, murder, you,...  \n",
       "1      [coming, the, borders, and, will, kill, you, all]  \n",
       "2      [getting, borderlands, and, will, kill, you, all]  \n",
       "3      [coming, borderlands, and, will, murder, you, ...  \n",
       "4      [getting, borderlands, and, will, murder, you,...  \n",
       "...                                                  ...  \n",
       "74677  [just, realized, that, the, windows, partition...  \n",
       "74678  [just, realized, that, mac, window, partition,...  \n",
       "74679  [just, realized, the, windows, partition, mac,...  \n",
       "74680  [just, realized, between, the, windows, partit...  \n",
       "74681  [just, like, the, windows, partition, mac, lik...  \n",
       "\n",
       "[74682 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "970bc66c-638e-4842-b3dd-42d491e10d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary.remove_stop_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b939301-f4f0-4a6b-b200-0dba598ef6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary.train['content'].astype(str).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d13fcd5a-215e-45e7-a675-11ca0cae8e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary.remove_hapaxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f96736ae-1c8e-403b-ba2f-60c9d7759216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "      <td>[getting, borderlands, murder]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>[coming, borders, kill]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>[getting, borderlands, kill]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>[coming, borderlands, murder]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>[getting, borderlands, murder]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74677</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that the Windows partition of my...</td>\n",
       "      <td>[realized, windows, partition, mac, like, year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74678</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that my Mac window partition is ...</td>\n",
       "      <td>[realized, mac, window, partition, years, behi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74679</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized the windows partition of my Mac ...</td>\n",
       "      <td>[realized, windows, partition, mac, years, beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74680</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized between the windows partition of...</td>\n",
       "      <td>[realized, windows, partition, mac, like, year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74681</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just like the windows partition of my Mac is l...</td>\n",
       "      <td>[like, windows, partition, mac, like, years, b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74682 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                            content  \\\n",
       "0      Positive  im getting on borderlands and i will murder yo...   \n",
       "1      Positive  I am coming to the borders and I will kill you...   \n",
       "2      Positive  im getting on borderlands and i will kill you ...   \n",
       "3      Positive  im coming on borderlands and i will murder you...   \n",
       "4      Positive  im getting on borderlands 2 and i will murder ...   \n",
       "...         ...                                                ...   \n",
       "74677  Positive  Just realized that the Windows partition of my...   \n",
       "74678  Positive  Just realized that my Mac window partition is ...   \n",
       "74679  Positive  Just realized the windows partition of my Mac ...   \n",
       "74680  Positive  Just realized between the windows partition of...   \n",
       "74681  Positive  Just like the windows partition of my Mac is l...   \n",
       "\n",
       "                                                  tokens  \n",
       "0                         [getting, borderlands, murder]  \n",
       "1                                [coming, borders, kill]  \n",
       "2                           [getting, borderlands, kill]  \n",
       "3                          [coming, borderlands, murder]  \n",
       "4                         [getting, borderlands, murder]  \n",
       "...                                                  ...  \n",
       "74677  [realized, windows, partition, mac, like, year...  \n",
       "74678  [realized, mac, window, partition, years, behi...  \n",
       "74679  [realized, windows, partition, mac, years, beh...  \n",
       "74680  [realized, windows, partition, mac, like, year...  \n",
       "74681  [like, windows, partition, mac, like, years, b...  \n",
       "\n",
       "[74682 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ba51230-6eba-4387-bc25-9fbabdf4fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary.stemming()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a5e24c3-de83-472b-a7af-ceb2c35bc471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "      <td>[get, borderland, murder]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>[come, border, kill]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>[get, borderland, kill]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>[come, borderland, murder]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>[get, borderland, murder]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74677</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that the Windows partition of my...</td>\n",
       "      <td>[realiz, window, partit, mac, like, year, behi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74678</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that my Mac window partition is ...</td>\n",
       "      <td>[realiz, mac, window, partit, year, behind, nv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74679</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized the windows partition of my Mac ...</td>\n",
       "      <td>[realiz, window, partit, mac, year, behind, nv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74680</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized between the windows partition of...</td>\n",
       "      <td>[realiz, window, partit, mac, like, year, behi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74681</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Just like the windows partition of my Mac is l...</td>\n",
       "      <td>[like, window, partit, mac, like, year, behind...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74682 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                            content  \\\n",
       "0      Positive  im getting on borderlands and i will murder yo...   \n",
       "1      Positive  I am coming to the borders and I will kill you...   \n",
       "2      Positive  im getting on borderlands and i will kill you ...   \n",
       "3      Positive  im coming on borderlands and i will murder you...   \n",
       "4      Positive  im getting on borderlands 2 and i will murder ...   \n",
       "...         ...                                                ...   \n",
       "74677  Positive  Just realized that the Windows partition of my...   \n",
       "74678  Positive  Just realized that my Mac window partition is ...   \n",
       "74679  Positive  Just realized the windows partition of my Mac ...   \n",
       "74680  Positive  Just realized between the windows partition of...   \n",
       "74681  Positive  Just like the windows partition of my Mac is l...   \n",
       "\n",
       "                                                  tokens  \n",
       "0                              [get, borderland, murder]  \n",
       "1                                   [come, border, kill]  \n",
       "2                                [get, borderland, kill]  \n",
       "3                             [come, borderland, murder]  \n",
       "4                              [get, borderland, murder]  \n",
       "...                                                  ...  \n",
       "74677  [realiz, window, partit, mac, like, year, behi...  \n",
       "74678  [realiz, mac, window, partit, year, behind, nv...  \n",
       "74679  [realiz, window, partit, mac, year, behind, nv...  \n",
       "74680  [realiz, window, partit, mac, like, year, behi...  \n",
       "74681  [like, window, partit, mac, like, year, behind...  \n",
       "\n",
       "[74682 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0563c6d4-f4d7-4cc0-9e8f-364a6c9d0fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train = gensim.models.Word2Vec(vocabulary.train.head()['tokens'].sum(), min_count = 1,window = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1bd0fd10-614c-49ec-95d1-c9176fc44c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x20769700fa0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ada3c6d4-6511-490b-b350-693dbba209f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "path_to_data = 'GRU/data'\n",
    "path_to_train = os.path.join(path_to_data, 'twitter_training.csv')\n",
    "path_to_test = os.path.join(path_to_data, 'twitter_validation.csv')\n",
    "\n",
    "# Applying the vocabulary\n",
    "\n",
    "ps = PorterStemmer()\n",
    "\n",
    "vocabulary = Vocabulary(path_to_train, path_to_test, stemmer = ps)\n",
    "train_set, test_set = vocabulary.preprocess()\n",
    "\n",
    "\n",
    "train_dataset = Data(train_set)\n",
    "test_dataset = Data(test_set)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=32, shuffle=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=32, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146e7d5a-30ff-4945-a210-52191fb57c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing model\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "#Initializing model with nr of features from input\n",
    "model = GRU().to(DEVICE)\n",
    "\n",
    "#Optimizer and los„s funtion\n",
    "optimizer = optim.Adam(model.parameters(),lr=learning_rate)\n",
    "loss_fn = nn.BCELoss()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112853a3-c201-4bbe-ab6b-34d985d551d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running training loop on the data with set parameters\n",
    "training_loop(\n",
    "    n_epochs=10,\n",
    "    optimizer=optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    print_plot=True,\n",
    "    train_loader=train_loader,\n",
    "    test_loader = test_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c67882b-3c2b-469a-96ef-1f1ed41335f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model retrain\n",
    "\n",
    "# Testing model\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "#Initializing model with nr of features from input\n",
    "model = GRU().to(DEVICE)\n",
    "\n",
    "#Optimizer and los„s funtion\n",
    "optimizer = optim.Adam(model.parameters(),lr=learning_rate)\n",
    "loss_fn = nn.BCELoss() \n",
    "\n",
    "#Running training loop on the data with set parameters\n",
    "training_loop(\n",
    "    n_epochs=10,\n",
    "    optimizer=optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    print_plot=True,\n",
    "    train_loader=train_loader,\n",
    "    test_loader = test_loader\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
